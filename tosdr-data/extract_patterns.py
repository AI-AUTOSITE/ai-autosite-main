#!/usr/bin/env python3
"""
ToS;DR Privacy Pattern Extractor v4
===================================
ToS;DR API v4ã‹ã‚‰ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

ä½¿ç”¨æ–¹æ³•:
  python extract_patterns.py

ãƒ©ã‚¤ã‚»ãƒ³ã‚¹: CC BY-SA 3.0 (ToS;DRã®ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ¡ä»¶ã«æº–æ‹ )
"""

import json
import sys
import time
from pathlib import Path
from collections import defaultdict
from datetime import datetime

# requestsãŒãªã„å ´åˆã¯urllibã‚’ä½¿ç”¨
try:
    import requests
    USE_REQUESTS = True
except ImportError:
    import urllib.request
    import urllib.error
    import urllib.parse
    USE_REQUESTS = False
    print("INFO: requestsãŒãªã„ãŸã‚ã€urllibã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

# ========================================
# è¨­å®š
# ========================================
OUTPUT_FILE = "./privacy-patterns.json"
API_BASE_URL = "https://api.tosdr.org"

# ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ãƒªã‚¹ãƒˆ
MAJOR_SERVICES = [
    # è©•ä¾¡Aï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼è‰¯å¥½ï¼‰
    "duckduckgo", "signal", "protonmail", "firefox", "wikipedia",
    "nextcloud", "bitwarden", "tutanota", "mastodon",
    # è©•ä¾¡B-Cï¼ˆæ™®é€šï¼‰
    "github", "discord", "spotify", "netflix", "dropbox",
    "slack", "zoom", "microsoft", "apple", "reddit",
    "twitter", "linkedin", "pinterest", "twitch", "steam",
    # è©•ä¾¡D-Eï¼ˆãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼æ‡¸å¿µï¼‰
    "google", "facebook", "instagram", "tiktok", "amazon",
    "uber", "snapchat", "whatsapp", "youtube", "gmail"
]

# ========================================
# ã‚«ãƒ†ã‚´ãƒªå®šç¾©
# ========================================
CATEGORIES = {
    "data_collection": {
        "name": "Data Collection",
        "name_ja": "ãƒ‡ãƒ¼ã‚¿åé›†",
        "description": "What personal data is collected",
        "keywords": ["collect", "gather", "obtain", "access", "receive", "track", "log", "record", "store", "information you provide"]
    },
    "third_party_sharing": {
        "name": "Third Party Sharing", 
        "name_ja": "ç¬¬ä¸‰è€…å…±æœ‰",
        "description": "How data is shared with others",
        "keywords": ["share", "disclose", "third party", "third-party", "partner", "advertiser", "affiliate", "transfer", "sell your", "sold to"]
    },
    "data_retention": {
        "name": "Data Retention",
        "name_ja": "ãƒ‡ãƒ¼ã‚¿ä¿æŒ",
        "description": "How long data is kept",
        "keywords": ["retain", "keep", "store", "delete", "removal", "expire", "lifetime", "permanent", "indefinite"]
    },
    "user_rights": {
        "name": "User Rights",
        "name_ja": "ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¨©åˆ©",
        "description": "User control over their data",
        "keywords": ["opt-out", "opt out", "delete your", "access your", "export", "download your data", "correct", "modify", "rights", "request deletion", "gdpr", "ccpa"]
    },
    "security": {
        "name": "Security",
        "name_ja": "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
        "description": "How data is protected",
        "keywords": ["encrypt", "secure", "protect", "ssl", "https", "password", "breach", "hack", "security measures"]
    },
    "policy_changes": {
        "name": "Policy Changes",
        "name_ja": "ãƒãƒªã‚·ãƒ¼å¤‰æ›´",
        "description": "How users are notified of changes",
        "keywords": ["change", "modify terms", "update", "notify", "notice", "amend", "revise", "without notice"]
    },
    "legal": {
        "name": "Legal & Jurisdiction",
        "name_ja": "æ³•çš„äº‹é …",
        "description": "Legal terms and jurisdiction",
        "keywords": ["jurisdiction", "arbitration", "waive", "lawsuit", "court", "legal", "binding", "class action", "dispute"]
    },
    "advertising": {
        "name": "Advertising",
        "name_ja": "åºƒå‘Š",
        "description": "Targeted advertising practices",
        "keywords": ["advertis", "target", "personali", "marketing", "promotional", "behavioral"]
    },
    "cookies": {
        "name": "Cookies & Tracking",
        "name_ja": "Cookieãƒ»ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°",
        "description": "Use of cookies and tracking technologies",
        "keywords": ["cookie", "tracking", "pixel", "beacon", "analytics", "fingerprint"]
    }
}

# ========================================
# APIé–¢æ•°ï¼ˆv4å½¢å¼ï¼‰
# ========================================
def fetch_url(url):
    """URLã‹ã‚‰JSONãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
    try:
        if USE_REQUESTS:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            return response.json()
        else:
            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=30) as response:
                return json.loads(response.read().decode('utf-8'))
    except Exception as e:
        return None

def search_service_v4(query):
    """ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ¤œç´¢ï¼ˆv4 API - æ­£ã—ã„å½¢å¼ï¼‰"""
    # v4 APIã¯ ?query= ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å½¢å¼ã‚’ä½¿ç”¨
    if USE_REQUESTS:
        url = f"{API_BASE_URL}/search/v4/"
        try:
            response = requests.get(url, params={"query": query}, timeout=30)
            response.raise_for_status()
            return response.json()
        except:
            return None
    else:
        encoded_query = urllib.parse.quote(query)
        url = f"{API_BASE_URL}/search/v4/?query={encoded_query}"
        return fetch_url(url)

def get_service_by_id_v2(service_id):
    """ã‚µãƒ¼ãƒ“ã‚¹IDã§è©³ç´°ã‚’å–å¾—ï¼ˆv2 APIï¼‰"""
    if USE_REQUESTS:
        url = f"{API_BASE_URL}/service/v2"
        try:
            response = requests.get(url, params={"id": service_id}, timeout=30)
            response.raise_for_status()
            return response.json()
        except:
            return None
    else:
        url = f"{API_BASE_URL}/service/v2?id={service_id}"
        return fetch_url(url)

def get_all_cases():
    """å…¨ã‚±ãƒ¼ã‚¹ï¼ˆåˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã‚’å–å¾—"""
    url = f"{API_BASE_URL}/case/v2/"
    return fetch_url(url)

# ========================================
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ========================================
def classify_point(case_data):
    """ãƒã‚¤ãƒ³ãƒˆã®è©•ä¾¡ã‚’åˆ†é¡"""
    classification = case_data.get('classification', 'neutral')
    
    mapping = {
        'good': 'good',
        'neutral': 'neutral',
        'bad': 'bad',
        'blocker': 'critical'
    }
    
    return mapping.get(classification, 'neutral')

def categorize_text(title, description=""):
    """ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡"""
    text = f"{title} {description}".lower()
    categories_found = []
    
    for cat_id, cat_info in CATEGORIES.items():
        for keyword in cat_info['keywords']:
            if keyword.lower() in text:
                categories_found.append(cat_id)
                break
    
    return categories_found if categories_found else ['other']

# ========================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ========================================
def extract_patterns():
    """ToS;DR APIã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º"""
    
    print("=" * 60)
    print("ğŸ” ToS;DR Privacy Pattern Extractor v4")
    print("=" * 60)
    print("")
    
    # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆæœŸåŒ–
    patterns = {
        "metadata": {
            "source": "ToS;DR (Terms of Service; Didn't Read)",
            "source_url": "https://tosdr.org",
            "license": "CC BY-SA 3.0",
            "extracted_at": datetime.now().isoformat(),
            "total_services": 0,
            "total_points": 0
        },
        "categories": {},
        "patterns": {
            "critical": [],
            "bad": [],
            "warning": [],
            "neutral": [],
            "good": []
        },
        "keywords": {
            "negative": [],
            "positive": []
        },
        "services_reference": {}
    }
    
    # ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ã‚’åˆæœŸåŒ–
    for cat_id, cat_info in CATEGORIES.items():
        patterns["categories"][cat_id] = {
            "name": cat_info["name"],
            "name_ja": cat_info["name_ja"],
            "description": cat_info["description"],
            "count": 0
        }
    patterns["categories"]["other"] = {
        "name": "Other",
        "name_ja": "ãã®ä»–",
        "description": "Uncategorized points",
        "count": 0
    }
    
    # ã¾ãšå…¨ã‚±ãƒ¼ã‚¹ï¼ˆåˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã‚’å–å¾—
    print("ğŸ“‚ ã‚±ãƒ¼ã‚¹ï¼ˆåˆ†é¡ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰ã‚’å–å¾—ä¸­...")
    cases_data = get_all_cases()
    if cases_data:
        cases_list = cases_data.get('parameters', [])
        print(f"   â†’ {len(cases_list)} ã‚±ãƒ¼ã‚¹ã‚’å–å¾—")
    else:
        print("   âš ï¸ ã‚±ãƒ¼ã‚¹ã®å–å¾—ã«å¤±æ•—ï¼ˆç¶šè¡Œã—ã¾ã™ï¼‰")
        cases_list = []
    
    # ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
    print("")
    print(f"ğŸ“¡ {len(MAJOR_SERVICES)} ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­...")
    print("   (v4 Search API + v2 Service API ã‚’ä½¿ç”¨)")
    print("")
    
    point_count = 0
    processed = 0
    seen_titles = set()  # é‡è¤‡ãƒã‚§ãƒƒã‚¯ç”¨
    
    for i, service_name in enumerate(MAJOR_SERVICES):
        # é€²æ—è¡¨ç¤º
        progress = f"[{i+1}/{len(MAJOR_SERVICES)}]"
        print(f"   {progress} {service_name}...", end=" ", flush=True)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚’æ¤œç´¢ï¼ˆv4 APIï¼‰
        search_result = search_service_v4(service_name)
        if not search_result:
            print("âš ï¸ search failed")
            time.sleep(0.5)
            continue
        
        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’ç¢ºèª
        params = search_result.get('parameters', {})
        services = params.get('services', []) or params.get('service', [])
        
        if not services:
            print("âš ï¸ no results")
            time.sleep(0.5)
            continue
        
        # æœ€åˆã®ãƒãƒƒãƒã‚’ä½¿ç”¨
        service = services[0]
        service_id = service.get('id')
        
        if not service_id:
            print("âš ï¸ no id")
            time.sleep(0.5)
            continue
        
        # ã‚µãƒ¼ãƒ“ã‚¹è©³ç´°ã‚’å–å¾—ï¼ˆv2 APIï¼‰
        details = get_service_by_id_v2(service_id)
        if not details:
            print("âš ï¸ details failed")
            time.sleep(0.5)
            continue
        
        detail_params = details.get('parameters', {})
        rating = detail_params.get('rating')
        actual_name = detail_params.get('name', service_name)
        
        # ã‚µãƒ¼ãƒ“ã‚¹å‚ç…§ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        patterns["services_reference"][str(service_id)] = {
            "name": actual_name,
            "rating": rating if rating else "N/A",
            "url": detail_params.get('urls', [''])[0] if detail_params.get('urls') else ''
        }
        
        # ãƒã‚¤ãƒ³ãƒˆã‚’å‡¦ç†
        points = detail_params.get('points', [])
        service_point_count = 0
        
        for point in points:
            case = point.get('case', {})
            if not case:
                continue
            
            title = case.get('title', '') or point.get('title', '')
            description = case.get('description', '')
            
            # ç„¡åŠ¹ãªãƒã‚¤ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
            if not title or title == 'none' or title.lower() == 'none':
                continue
            
            # é‡è¤‡ãƒã‚§ãƒƒã‚¯
            if title in seen_titles:
                continue
            seen_titles.add(title)
            
            classification = classify_point(case)
            categories = categorize_text(title, description)
            weight = case.get('weight', 50)
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
            pattern_entry = {
                "id": f"point-{case.get('id', point_count)}",
                "title": title,
                "summary": description[:300] if description else '',
                "score": min(100, max(0, weight)),
                "categories": categories,
                "services": [actual_name]
            }
            
            # åˆ†é¡ã«è¿½åŠ 
            if classification == 'critical':
                patterns["patterns"]["critical"].append(pattern_entry)
            elif classification == 'bad':
                patterns["patterns"]["bad"].append(pattern_entry)
            elif classification == 'good':
                patterns["patterns"]["good"].append(pattern_entry)
            else:
                patterns["patterns"]["neutral"].append(pattern_entry)
            
            # ã‚«ãƒ†ã‚´ãƒªã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°
            for cat in categories:
                if cat in patterns["categories"]:
                    patterns["categories"][cat]["count"] += 1
            
            point_count += 1
            service_point_count += 1
        
        rating_str = f"({rating})" if rating else ""
        print(f"âœ“ {service_point_count} points {rating_str}")
        processed += 1
        
        # APIåˆ¶é™ã‚’è€ƒæ…®ã—ã¦å¾…æ©Ÿ
        time.sleep(0.5)
    
    patterns["metadata"]["total_services"] = processed
    patterns["metadata"]["total_points"] = point_count
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    print("")
    print("ğŸ”¤ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºä¸­...")
    
    # æ‚ªã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    negative_words = defaultdict(int)
    for pattern in patterns["patterns"]["critical"] + patterns["patterns"]["bad"]:
        words = pattern["title"].lower().split()
        for word in words:
            if len(word) > 4 and word.isalpha():
                negative_words[word] += 1
    
    patterns["keywords"]["negative"] = [
        {"word": word, "score": count * 10}
        for word, count in sorted(negative_words.items(), key=lambda x: -x[1])[:50]
    ]
    
    # è‰¯ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã‹ã‚‰ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º
    positive_words = defaultdict(int)
    for pattern in patterns["patterns"]["good"]:
        words = pattern["title"].lower().split()
        for word in words:
            if len(word) > 4 and word.isalpha():
                positive_words[word] += 1
    
    patterns["keywords"]["positive"] = [
        {"word": word, "score": count * 10}
        for word, count in sorted(positive_words.items(), key=lambda x: -x[1])[:50]
    ]
    
    # çµ±è¨ˆã‚’è¡¨ç¤º
    print("")
    print("=" * 60)
    print("ğŸ“Š æŠ½å‡ºçµæœ:")
    print("=" * 60)
    print(f"   å‡¦ç†ã—ãŸã‚µãƒ¼ãƒ“ã‚¹: {processed}")
    print(f"   åˆè¨ˆãƒã‚¤ãƒ³ãƒˆ: {point_count}")
    print("")
    print(f"   ğŸ”´ Critical: {len(patterns['patterns']['critical'])} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print(f"   ğŸŸ  Bad:      {len(patterns['patterns']['bad'])} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print(f"   ğŸŸ¢ Good:     {len(patterns['patterns']['good'])} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print(f"   âšª Neutral:  {len(patterns['patterns']['neutral'])} ãƒ‘ã‚¿ãƒ¼ãƒ³")
    print("")
    print("   ã‚«ãƒ†ã‚´ãƒªåˆ¥:")
    for cat_id, cat_data in sorted(patterns["categories"].items(), key=lambda x: -x[1]["count"]):
        if cat_data["count"] > 0:
            print(f"     - {cat_data['name']}: {cat_data['count']}")
    
    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    output_path = Path(OUTPUT_FILE)
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(patterns, f, ensure_ascii=False, indent=2)
    
    file_size = output_path.stat().st_size / 1024
    print("")
    print("=" * 60)
    print(f"âœ… ä¿å­˜å®Œäº†: {OUTPUT_FILE} ({file_size:.1f} KB)")
    print("=" * 60)
    
    return patterns

# ========================================
# ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
# ========================================
if __name__ == "__main__":
    print("")
    print("ToS;DR API v4ã‹ã‚‰ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚")
    print("ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦ã§ã™ï¼ˆç´„2-3åˆ†ï¼‰ã€‚")
    print("")
    
    try:
        result = extract_patterns()
        if result and result["metadata"]["total_points"] > 0:
            print("")
            print("ğŸ‰ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
            print("   Copy-Item privacy-patterns.json ..\\app\\lib\\")
            print("")
        else:
            print("")
            print("âš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            print("   ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()